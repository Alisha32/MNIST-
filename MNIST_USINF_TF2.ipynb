{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GIVEN DATSETS WITH 70,000 IMAGES, WE HAVE TO PREDICT THE NUMBERS\n",
        "# NUMBERS CAN BE 0,1,2,3,4,5,6,7,8,9\n",
        "# DEFINE AN ALGORITHM TO DETECT WHICH NUMBER IS WRITTEN\n",
        "# CLASSIFICARTION PROBLEM WITH 10 CLASSES\n"
      ],
      "metadata": {
        "id": "2KxzId4NKUYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QbjJaEZhIpFy"
      },
      "outputs": [],
      "source": [
        "#importing relevant libraraies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking whether tensorflow is working or not by using below command\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPYKbqCNIrT1",
        "outputId": "2a727526-749a-4f4c-e236-647b34b3760d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing datasets\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "eBxptXjZIwOS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset,mnist_info=tfds.load(name='mnist',with_info=True,as_supervised=True)\n",
        "#with_info gives whole info about the dataset which gets stored in the mnist_info.\n",
        "# as_supervised spits the data into inputs and targets."
      ],
      "metadata": {
        "id": "bcF7vEc-I3FA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train,mnist_test=mnist_dataset['train'],mnist_dataset['test']\n",
        "#validation?--- 10 % of training dataset\n",
        "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
        "num_validation_samples = tf.cast(num_validation_samples,tf.int64)\n",
        "#(tf.cast==converts into specified type)\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "num_test_samples = tf.cast(num_test_samples,tf.int64)\n",
        "#SCALING \n",
        "def scale(image,label):\n",
        "  image = tf.cast(image,tf.float32)\n",
        "  image/=255.\n",
        "  return image,label\n",
        "scaled_train_and_validation_data=mnist_train.map(scale)\n",
        "test_data=mnist_test.map(scale)\n",
        "#SHUFFLING\n",
        "buffer_size=10000\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(buffer_size)\n",
        "#validation data and train data splitting\n",
        "validation_data=shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data=shuffled_train_and_validation_data.skip(num_validation_samples)\n",
        "#BATCHING\n",
        "batch_size=100\n",
        "train_data=train_data.batch(batch_size)\n",
        "validation_data=validation_data.batch(num_validation_samples)\n",
        "test_data=test_data.batch(num_test_samples)\n",
        "\n",
        "#AS SUPERVISED = TRUE , 2-tuples, inputs and targets\n",
        "validation_inputs,validation_targets=next(iter(validation_data))\n",
        "#'''next=load next batch\n",
        "#iter = make data iterable(for and while loop as)'''"
      ],
      "metadata": {
        "id": "NkoKyua5pQg7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OUTLINING THE MODEL\n",
        "input_size=784\n",
        "output_size=10\n",
        "hidden_layer_size=50\n",
        "model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
        "        tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
        "        tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
        "        tf.keras.layers.Dense(output_size,activation='Softmax')\n",
        "])\n",
        "\n",
        "#tf.keras.Sequential--stack the layers\n",
        "#tf.keras.layers.Flatten--trnaforms into vectors readable\n",
        "#tf.keras.layers.Dense(sizes,activation functions to be used)\n"
      ],
      "metadata": {
        "id": "4yZuGUUbrjBA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LEARNING\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "#.compile takes arguments as optimizer and loss function and metrics such as accuracy to know"
      ],
      "metadata": {
        "id": "niBup2d325Gg"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING\n",
        "NUM_EPOCHS=5\n",
        "model.fit(train_data,epochs=NUM_EPOCHS,validation_data=(validation_inputs,validation_targets),verbose=2)\n",
        "#.fit fits the dataset and at starting of each epoch,training loss=0\n",
        "# iterate over preset number of batches\n",
        "#weights and biases are updated as many times as tehir are batches\n",
        "# velue of loss function\n",
        "# training is going\n",
        "#training accuarcy\n",
        "# at end of each epoch,will forward propagate validation dataset."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzAvVqhW4GZf",
        "outputId": "93a08e93-84d0-4238-cbfc-c3f8f5e81ebe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 13s - loss: 0.4031 - accuracy: 0.8861 - val_loss: 0.2267 - val_accuracy: 0.9373 - 13s/epoch - 24ms/step\n",
            "Epoch 2/5\n",
            "540/540 - 6s - loss: 0.1877 - accuracy: 0.9456 - val_loss: 0.1670 - val_accuracy: 0.9523 - 6s/epoch - 11ms/step\n",
            "Epoch 3/5\n",
            "540/540 - 5s - loss: 0.1450 - accuracy: 0.9573 - val_loss: 0.1356 - val_accuracy: 0.9618 - 5s/epoch - 9ms/step\n",
            "Epoch 4/5\n",
            "540/540 - 6s - loss: 0.1217 - accuracy: 0.9635 - val_loss: 0.1199 - val_accuracy: 0.9645 - 6s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "540/540 - 5s - loss: 0.1018 - accuracy: 0.9700 - val_loss: 0.1038 - val_accuracy: 0.9692 - 5s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71f22bbf40>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TESTING\n",
        "test_loss,test_accuracy=model.evaluate(test_data)\n",
        "# determines te loss and accuracy metrics for the testig data\n",
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
        "#compare with the validation accuracy!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zeKDsF9GYDS",
        "outputId": "f5e47c89-aade-4f7d-c17f-111e57710514"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1126 - accuracy: 0.9664\n",
            "Test loss: 0.11. Test accuracy: 96.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing accuarcy is 96.64% whereas the validation accuracy is 96.92%\n",
        "# The two are quite close, our model is well defined\n"
      ],
      "metadata": {
        "id": "C_jtAcOUKTYX"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}